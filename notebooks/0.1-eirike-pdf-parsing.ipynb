{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Iterator, List\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTPage\n",
    "from collections import Counter\n",
    "\n",
    "def read_file(file_name):\n",
    "    file = extract_pages(file_name)\n",
    "    return file\n",
    "    \n",
    "    \n",
    "def get_paragraphs(file: Iterator[LTPage]) -> List[dict]:\n",
    "    paragraphs = []\n",
    "    page_num = 0\n",
    "    paragraph_id = 0\n",
    "    for page_layout in file:\n",
    "        page_num += 1\n",
    "        \n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "                paragraphs.append({\n",
    "                    'id': paragraph_id,\n",
    "                    'page': page_num,\n",
    "                    'paragraph': element.get_text()\n",
    "                })\n",
    "                paragraph_id += 1\n",
    "                \n",
    "    return paragraphs\n",
    "\n",
    "def get_terms(file: Iterator[LTPage]) -> List[dict]:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total paragraphs: 386\n",
      "Actual paragraphs: 109\n"
     ]
    }
   ],
   "source": [
    "in_file = read_file('../data/raw/Chapter-1---The-Rise-of-Platform-Ecosystems_2014_Platform-Ecosystems.pdf')\n",
    "paragraphs = get_paragraphs(in_file)\n",
    "\n",
    "print(f\"Total paragraphs: {len(paragraphs)}\")\n",
    "print(f\"Actual paragraphs: {len([p for p in paragraphs if len(p['paragraph']) > 30])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from openai import OpenAI\n",
    "from src.api_integrations.interfaces.llm_generic_interface import LLMGenericInterface\n",
    "\n",
    "\n",
    "class OpenAIInterface(LLMGenericInterface):\n",
    "    \n",
    "    client = None\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.setup()\n",
    "        \n",
    "    def setup(self, environment: bool = False):\n",
    "        if not environment:\n",
    "            dotenv_path = find_dotenv()\n",
    "            load_dotenv(dotenv_path)\n",
    "        \n",
    "        self.client = OpenAI()\n",
    "            \n",
    "            \n",
    "    \n",
    "    def sys_message(self, message: str):\n",
    "        return {\"role\": \"system\", \"content\": message}\n",
    "    \n",
    "    def user_message(self, message: str):\n",
    "        return {\"role\": \"user\", \"content\": message}\n",
    "    \n",
    "    prompts = {\n",
    "        \"expert_tutor\": \"You are an expert tutor. Give an extensive and descriptive answer using relevant technical terms and examples.\",\n",
    "        \"profile_picture\": \"Create an avatar of a happy robot tutor in the course {course_name}. Make the robot be the highlight, with a background displaying a simple pattern\",\n",
    "        \"summerize_paragraph\": \"Summerize the user's paragraph in one descriptive sentence. Focus on keeping relevant technical terms and keep it short but concise.\",\n",
    "    }\n",
    "        \n",
    "      \n",
    "    def generic_request(self, query: str, params: dict = None, history_key: str = None) -> str | List[str]:\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.prompts[\"expert tutor\"]},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return completion.choices[0].text\n",
    "    \n",
    "    def summerize_paragraph(self, text: str) -> str:\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            temperature=0.3,\n",
    "            top_p=0.1,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.prompts[\"summerize_paragraph\"]},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return completion.choices[0].message.content\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_paragraph = \"Blackberry had everything going right. It had fanatically loyal customers and its products were inno-\\\n",
    "vative, well engineered, durable, and got raving reviews from critics. After years of commanding a\\\n",
    "lion’s share (about 50%) of the smartphone market that it largely created, it had trouble breaking past\\\n",
    "a 1% market share with its newest products by 2012, leading to its subsequent downfall Blackberry\\\n",
    "assumed that the problem was Apple and then Google—both industry outsiders—who had since\\\n",
    "entered the fray. So, it did what made sense: Price more competitively, invest more in developing\\\n",
    "new products, upgrade its operating system, and step up marketing. Nothing worked. Its error was fail-\\\n",
    "ning to realize that the basis for competition had changed: It was no longer Blackberry against Apple\\\n",
    "smartphones. Instead, it was the Blackberry ecosystem against the iOS ecosystem. It was not one prod-\\\n",
    "uct against another but Blackberry’s army of 8000 external innovators against Apple’s 200,000. Black-\\\n",
    "berry’s mistake was failing to realize the ecosystem on which its continued success depended. All three\\\n",
    "companies made good products, but the lack of enough innovative apps muted Blackberry’s market\\\n",
    "potential. It was already too late to catch up by the time Blackberry realized that the competitive blue-\\\n",
    "print had shifted. The Red Queen effect — the need to run faster just to stay in the same place—had\\\n",
    "taken over.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original length: 1401, summary length: 353\n",
      "summary: Blackberry's downfall was due to its failure to recognize the shift in competition from individual smartphones to the broader ecosystem, resulting in an inability to keep up with Apple's expansive network of innovators and the critical mass of innovative apps, despite making competitive pricing, product development, OS upgrades, and marketing efforts.\n"
     ]
    }
   ],
   "source": [
    "model = OpenAIInterface()\n",
    "\n",
    "response = model.summerize_paragraph(example_paragraph)\n",
    "print(f\"original length: {len(example_paragraph)}, summary length: {len(response)}\")\n",
    "print(f\"summary: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
